https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview

HTTP
	HTTP is a protocol for fetching resources such as HTML documents. It is the foundation of any data exchange on the Web and it is a client-server protocol, which means requests are
	initiated by the recipient, usually the Web browser. A complete document is reconstructed from the different sub-documents fetched, for instance, text, layout description, images,
	videos, scripts, and more. 
	Designed in the early 1990s, HTTP is an extensible protocol which has evolved over time. It is an application layer protocol that is sent over TCP, or over a TLS-encrypted TCP
	connection, though any reliable transport protocol could theoretically be used. Due to its extensibility, it is used to not only fetch hypertext documents, but also images and
	videos or to post content to servers, like with HTML form results. HTTP can also be used to fetch parts of documents to update Web pages on demand. 
	HTTP is a client-server protocol: requests are sent by one entity, the user-agent (or a proxy on behalf of it). Most of the time the user-agent is a Web browser, but it can be
	anything, for example, a robot that crawls the Web to populate and maintain a search engine index.
	Each individual request is sent to a server, which handles it and provides an answer called the response. Between the client and the server there are numerous entities,
	collectively called proxies, which perform different operations and act as gateways or caches, for example. 

Client: the user-agent
	The user-agent is any tool that acts on behalf of the user. This role is primarily performed by the Web browser, but it may also be performed by programs used by engineers and Web
	developers to debug their applications.
	The browser is always the entity initiating the request. It is never the server (though some mechanisms have been added over the years to simulate server-initiated messages).
	To display a Web page, the browser sends an original request to fetch the HTML document that represents the page. It then parses this file, making additional requests
	corresponding to execution scripts, layout information (CSS) to display, and sub-resources contained within the page (usually images and videos). The Web browser then combines
	these resources to present the complete document, the Web page. Scripts executed by the browser can fetch more resources in later phases and the browser updates the Web page
	accordingly.
	A Web page is a hypertext document. This means some parts of the displayed content are links, which can be activated (usually by a click of the mouse) to fetch a new Web page,
	allowing the user to direct their user-agent and navigate through the Web. The browser translates these directions into HTTP requests, and further interprets the HTTP responses to
	present the user with a clear response. 

The Web server
	On the opposite side of the communication channel is the server, which serves the document as requested by the client. A server appears as only a single machine virtually; but it
	may actually be a collection of servers sharing the load (load balancing), or a complex piece of software interrogating other computers (like cache, a DB server, or e-commerce
	servers), totally or partially generating the document on demand.
	A server is not necessarily a single machine, but several server software instances can be hosted on the same machine. With HTTP/1.1 and the Host header, they may even share the
	same IP address. 

Proxies
	A proxy server is an intermediate program or computer used when navigating through different networks of the Internet. They facilitate access to content on the World Wide Web. A
	proxy intercepts requests and serves back responses; it may forward the requests, or not (for example in the case of a cache), and it may modify it (for example changing its
	headers, at the boundary between two networks).
	A proxy can be on the user's local computer, or anywhere between the user's computer and a destination server on the Internet. In general there are two main types of proxy servers:
		- A forward proxy that handles requests from and to anywhere on the Internet.
		- A reverse proxy taking requests from the Internet and forwarding them to servers in an internal network.
	Between the Web browser and the server, numerous computers and machines relay the HTTP messages. Due to the layered structure of the Web stack, most of these operate at the
	transport, network or physical levels, becoming transparent at the HTTP layer and potentially having a significant impact on performance. Those operating at the application layers
	are generally called proxies. These can be transparent, forwarding on the requests they receive without altering them in any way, or non-transparent, in which case they will
	change the request in some way before passing it along to the server. Proxies may perform numerous functions:
		- caching (the cache can be public or private, like the browser cache)
		- filtering (like an antivirus scan or parental controls)
		- load balancing (to allow multiple servers to serve different requests)
		- authentication (to control access to different resources)
		- logging (allowing the storage of historical information)
	More here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Proxy_servers_and_tunneling

Basic aspects of HTTP
	• HTTP is simple
		HTTP is generally designed to be simple and human readable, even with the added complexity introduced in HTTP/2 by encapsulating HTTP messages into frames. HTTP messages can
		be read and understood by humans, providing easier testing for developers, and reduced complexity for newcomers. 
	
	• HTTP is extensible
		Introduced in HTTP/1.0, HTTP headers make this protocol easy to extend and experiment with. New functionality can even be introduced by a simple agreement between a client and
		a server about a new header's semantics. 
	
	• HTTP is stateless, but not sessionless
		HTTP is stateless: there is no link between two requests being successively carried out on the same connection. This immediately has the prospect of being problematic for
		users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets. But while the core of HTTP itself is stateless, HTTP cookies allow
		the use of stateful sessions. Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or
		the same state. 
	
	• HTTP and connections
		A connection is controlled at the transport layer, and therefore fundamentally out of scope for HTTP. HTTP doesn't require the underlying transport protocol to be
		connection-based; it only requires it to be reliable, or not lose messages (at minimum, presenting an error in such cases). Among the two most common transport protocols on
		the Internet, TCP is reliable and UDP isn't. HTTP therefore relies on the TCP standard, which is connection-based.
		Before a client and server can exchange an HTTP request/response pair, they must establish a TCP connection, a process which requires several round-trips. The default behavior
		of HTTP/1.0 is to open a separate TCP connection for each HTTP request/response pair. This is less efficient than sharing a single TCP connection when multiple requests are
		sent in close succession. 
		In order to mitigate this flaw, HTTP/1.1 introduced pipelining (which proved difficult to implement) and persistent connections: the underlying TCP connection can be partially
		controlled using the Connection header. HTTP/2 went a step further by multiplexing messages over a single connection, helping keep the connection warm and more efficient.

HTTP flow
	When a client wants to communicate with a server, either the final server or an intermediate proxy, it performs the following steps:
		1 Open a TCP connection: The TCP connection is used to send a request, or several, and receive an answer. The client may open a new connection, reuse an existing connection,
		or open several TCP connections to the servers.
		2 Send an HTTP message: HTTP messages (before HTTP/2) are human-readable. With HTTP/2, these simple messages are encapsulated in frames, making them impossible to read directly,
		but the principle remains the same. For example: 
			GET / HTTP/1.1
			Host: developer.mozilla.org
			Accept-Language: fr
		3 Read the response sent by the server, such as:
			HTTP/1.1 200 OK
			Date: Sat, 09 Oct 2010 14:28:02 GMT
			Server: Apache
			Last-Modified: Tue, 01 Dec 2009 20:18:22 GMT
			ETag: "51142bc1-7449-479b075b2891b"
			Accept-Ranges: bytes
			Content-Length: 29769
			Content-Type: text/html

			<!DOCTYPE html>… (here come the 29769 bytes of the requested web page)

		4 Close or reuse the connection for further requests.
	
	If HTTP pipelining is activated, several requests can be sent without waiting for the first response to be fully received.

HTTP messages
	HTTP messages, as defined in HTTP/1.1 and earlier, are human-readable. In HTTP/2, these messages are embedded into a binary structure, a frame, allowing optimizations like compression
	of headers and multiplexing. Even if only part of the original HTTP message is sent in this version of HTTP, the semantics of each message is unchanged and the client reconstitutes (virtually)
	the original HTTP/1.1 request. It is therefore useful to comprehend HTTP/2 messages in the HTTP/1.1 format. 

	Requests consist of the following elements:
		- An HTTP method, usually a verb like GET, POST, or a noun like OPTIONS or HEAD that defines the operation the client wants to perform. Typically, a client wants to fetch a resource
		(using GET) or post the value of an HTML form (using POST), though more operations may be needed in other cases.
		- The path of the resource to fetch; the URL of the resource stripped from elements that are obvious from the context, for example without the protocol (http://), the domain (here, developer.mozilla.org),
		or the TCP port (here, 80).
		- The version of the HTTP protocol.
		- Optional headers that convey additional information for the servers.
		- A body, for some methods like POST, similar to those in responses, which contain the resource sent.
	
	Responses consist of the following elements:
		- The version of the HTTP protocol they follow.
		- A status code, indicating if the request was successful or not, and why.
		- A status message, a non-authoritative short description of the status code.
		- HTTP headers, like those for requests.
		- Optionally, a body containing the fetched resource.

	More here:
		- https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages
		- webserv/thomas/tutos/trungams.txt
	
	Headers:
		HTTP headers let the client and the server pass additional information with an HTTP request or response. 
		An HTTP header consists of its case-insensitive name followed by a colon (:), then by its value. Whitespace before the value is ignored.
		Headers can be grouped according to their contexts:
			- Request headers contain more information about the resource to be fetched, or about the client requesting the resource.
			- Response headers hold additional information about the response, like its location or about the server providing it.
			- Representation headers contain information about the body of the resource, like its MIME type, or encoding/compression applied.
			- Payload headers contain representation-independent information about payload data, including content length and the encoding used for transport.
		
		More here: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers
	
	HTTP request methods
		HTTP defines a set of request methods to indicate the desired action to be performed for a given resource.
		
		GET
			The HTTP GET method requests a representation of the specified resource. Requests using GET should only be used to request data
		
		POST
			https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/POST
			The HTTP POST method sends data to the server. The type of the body of the request is indicated by the Content-Type header.
			
			Note: difference with PUT: 
				calling PUT once or several times successively has the same effect (that is no side effect),
				where successive identical POST may have additional effects, like passing an order several times.
			
			A POST request is typically sent via an HTML form and results in a change on the server. 
			In this case, the content type is selected by putting the adequate string 
				in the enctype attribute of the <form> element or
				in the formenctype attribute of the <input> or <button> elements			
			Content type:
				application/x-www-form-urlencoded: the keys and values are encoded in key-value tuples separated by '&', with a '=' between the key and the value. Non-alphanumeric characters in both keys and values are percent encoded: this is the reason why this type is not suitable to use with binary data (use multipart/form-data instead)
				multipart/form-data: each value is sent as a block of data ("body part"), with a user agent-defined delimiter ("boundary") separating each part. The keys are given in the Content-Disposition header of each part.
				text/plain
			
			Examples
				A simple form using the default application/x-www-form-urlencoded content type:
					POST /test HTTP/1.1
					Host: foo.example
					Content-Type: application/x-www-form-urlencoded
					Content-Length: 27

					field1=value1&field2=value2
					
				A form using the multipart/form-data content type:
					POST /test HTTP/1.1
					Host: foo.example
					Content-Type: multipart/form-data;boundary="boundary"

					--boundary
					Content-Disposition: form-data; name="field1"

					value1
					--boundary
					Content-Disposition: form-data; name="field2"; filename="example.txt"

					value2
					--boundary--

		DELETE
			The HTTP DELETE request method deletes the specified resource. 
			
			Example
				DELETE /file.html HTTP/1.1
				Host: example.com

			If a DELETE method is successfully applied, there are several response status codes possible:
				- A 202 (Accepted) status code if the action will likely succeed but has not yet been enacted.
				- A 204 (No Content) status code if the action has been enacted and no further information is to be supplied.
				- A 200 (OK) status code if the action has been enacted and the response message includes a representation describing the status.

	HTTP response status codes
		https://developer.mozilla.org/en-US/docs/Web/HTTP/Status
		Indicates whether a specific HTTP request has been successfully completed. Responses are grouped in five classes:
			- Informational responses (100 – 199)
			- Successful responses (200 – 299)
			- Redirection messages (300 – 399)
			- Client error responses (400 – 499)
			- Server error responses (500 – 599)	

HTTP/1.1
	The first standardized version of HTTP, HTTP/1.1, was published in early 1997, only a few months after HTTP/1.0.
	Improvements:
		- A connection could be reused, which saved time. It no longer needed to be opened multiple times to display the resources embedded in the single original document.
		- Pipelining was added. This allowed a second request to be sent before the answer to the first one was fully transmitted. This lowered the latency of the communication.
		- Chunked responses were also supported.
		- Additional cache control mechanisms were introduced.
		- Content negotiation, including language, encoding, and type, was introduced. A client and a server could now agree on which content to exchange.
		- Thanks to the Host header, the ability to host different domains from the same IP address allowed server collocation.

	HTTP/1.1 was first published as RFC 2068 in January 1997.
	The extensibility of HTTP made it easy to create new headers and methods. Even though the HTTP/1.1 protocol was refined over two revisions, RFC 2616 published in June 1999 and RFC 7230-RFC 7235 published in June 2014
	before the release of HTTP/2, it was extremely stable for more than 15 years.

	Typical flow requests, all through one single connection, look this:

		GET /en-US/docs/Glossary/Simple_header HTTP/1.1
		Host: developer.mozilla.org
		User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
		Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
		Accept-Language: en-US,en;q=0.5
		Accept-Encoding: gzip, deflate, br
		Referer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header

		200 OK
		Connection: Keep-Alive
		Content-Encoding: gzip
		Content-Type: text/html; charset=utf-8
		Date: Wed, 20 Jul 2016 10:55:30 GMT
		Etag: "547fa7e369ef56031dd3bff2ace9fc0832eb251a"
		Keep-Alive: timeout=5, max=1000
		Last-Modified: Tue, 19 Jul 2016 00:59:33 GMT
		Server: Apache
		Transfer-Encoding: chunked
		Vary: Cookie, Accept-Encoding

		(content)

		GET /static/img/header-background.png HTTP/1.1
		Host: developer.mozilla.org
		User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:50.0) Gecko/20100101 Firefox/50.0
		Accept: */*
		Accept-Language: en-US,en;q=0.5
		Accept-Encoding: gzip, deflate, br
		Referer: https://developer.mozilla.org/en-US/docs/Glossary/Simple_header

		200 OK
		Age: 9578461
		Cache-Control: public, max-age=315360000
		Connection: keep-alive
		Content-Length: 3077
		Content-Type: image/png
		Date: Thu, 31 Mar 2016 13:34:46 GMT
		Last-Modified: Wed, 21 Oct 2015 18:27:50 GMT
		Server: Apache

		(image content of 3077 bytes)

Using HTTP for secure transmissions
	The largest change to HTTP was made at the end of 1994. Instead of sending HTTP over a basic TCP/IP stack, the computer-services company Netscape Communications created an additional encrypted transmission layer 
	on top of it: SSL. SSL 1.0 was never released to the public, but SSL 2.0 and its successor SSL 3.0 allowed for the creation of ecommerce websites. To do this, they encrypted and guaranteed the authenticity of the
	messages exchanged between the server and client. SSL was eventually standardized and became TLS.

HTTP/2
	The HTTP/2 protocol differs from HTTP/1.1 in a few ways:
		- It's a binary protocol rather than a text protocol. It can't be read and created manually. Despite this hurdle, it allows for the implementation of improved optimization techniques.
		- It's a multiplexed protocol. Parallel requests can be made over the same connection, removing the constraints of the HTTP/1.x protocol.
		- It compresses headers. As these are often similar among a set of requests, this removes the duplication and overhead of data transmitted.
		- It allows a server to populate data in a client cache through a mechanism called the server push.
